{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python [default]",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "Traffic_Sign_Classifier.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZYPhJsTQeVV"
      },
      "source": [
        "import pickle\n",
        "\n",
        "def load_traffic_sign_data(training_file, testing_file):\n",
        "    with open(training_file, mode='rb') as f:\n",
        "        train = pickle.load(f)\n",
        "    with open(testing_file, mode='rb') as f:\n",
        "        test = pickle.load(f)\n",
        "    return train, test\n",
        "\n",
        "# Load pickled data\n",
        "train, test = load_traffic_sign_data('../traffic_signs_data/train.p', '../traffic_signs_data/test.p')\n",
        "    \n",
        "X_train, y_train = train['features'], train['labels']\n",
        "X_test, y_test = test['features'], test['labels']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZvhpjodQeVd"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Number of examples\n",
        "n_train, n_test = X_train.shape[0], X_test.shape[0]\n",
        "\n",
        "# What's the shape of an traffic sign image?\n",
        "image_shape = X_train[0].shape\n",
        "\n",
        "# How many classes?\n",
        "n_classes = np.unique(y_train).shape[0]\n",
        "\n",
        "print(\"Number of training examples =\", n_train)\n",
        "print(\"Number of testing examples  =\", n_test)\n",
        "print(\"Image data shape  =\", image_shape)\n",
        "print(\"Number of classes =\", n_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WaEIBLfQeVl"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# show a random sample from each class of the traffic sign dataset\n",
        "rows, cols = 4, 12\n",
        "fig, ax_array = plt.subplots(rows, cols)\n",
        "plt.suptitle('RANDOM SAMPLES FROM TRAINING SET (one for each class)')\n",
        "for class_idx, ax in enumerate(ax_array.ravel()):\n",
        "    if class_idx < n_classes:\n",
        "        # show a random image of the current class\n",
        "        cur_X = X_train[y_train == class_idx]\n",
        "        cur_img = cur_X[np.random.randint(len(cur_X))]\n",
        "        ax.imshow(cur_img)\n",
        "        ax.set_title('{:02d}'.format(class_idx))\n",
        "    else:\n",
        "        ax.axis('off')\n",
        "# hide both x and y ticks\n",
        "plt.setp([a.get_xticklabels() for a in ax_array.ravel()], visible=False)\n",
        "plt.setp([a.get_yticklabels() for a in ax_array.ravel()], visible=False)\n",
        "plt.draw()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UndrUh4HQeVs"
      },
      "source": [
        "# bar-chart of classes distribution\n",
        "train_distribution, test_distribution = np.zeros(n_classes), np.zeros(n_classes)\n",
        "for c in range(n_classes):\n",
        "    train_distribution[c] = np.sum(y_train == c) / n_train\n",
        "    test_distribution[c] = np.sum(y_test == c) / n_test\n",
        "fig, ax = plt.subplots()\n",
        "col_width = 0.5\n",
        "bar_train = ax.bar(np.arange(n_classes), train_distribution, width=col_width, color='r')\n",
        "bar_test = ax.bar(np.arange(n_classes)+col_width, test_distribution, width=col_width, color='b')\n",
        "ax.set_ylabel('PERCENTAGE OF PRESENCE')\n",
        "ax.set_xlabel('CLASS LABEL')\n",
        "ax.set_title('Classes distribution in traffic-sign dataset')\n",
        "ax.set_xticks(np.arange(0, n_classes, 5)+col_width)\n",
        "ax.set_xticklabels(['{:02d}'.format(c) for c in range(0, n_classes, 5)])\n",
        "ax.legend((bar_train[0], bar_test[0]), ('train set', 'test set'))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFIyJdAuQeV1"
      },
      "source": [
        "import cv2 \n",
        "\n",
        "def preprocess_features(X, equalize_hist=True):\n",
        "\n",
        "    # convert from RGB to YUV\n",
        "    X = np.array([np.expand_dims(cv2.cvtColor(rgb_img, cv2.COLOR_RGB2YUV)[:, :, 0], 2) for rgb_img in X])\n",
        "\n",
        "    # adjust image contrast\n",
        "    if equalize_hist:\n",
        "        X = np.array([np.expand_dims(cv2.equalizeHist(np.uint8(img)), 2) for img in X])\n",
        "\n",
        "    X = np.float32(X)\n",
        "\n",
        "    # standardize features\n",
        "    X -= np.mean(X, axis=0)\n",
        "    X /= (np.std(X, axis=0) + np.finfo('float32').eps)\n",
        "\n",
        "    return X\n",
        "\n",
        "X_train_norm = preprocess_features(X_train)\n",
        "X_test_norm = preprocess_features(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HmpvJuoQeV4"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# split into train and validation\n",
        "VAL_RATIO = 0.2\n",
        "X_train_norm, X_val_norm, y_train, y_val = train_test_split(X_train_norm, y_train, test_size=VAL_RATIO, random_state=0)\n",
        "\n",
        "\n",
        "# create the generator to perform online data augmentation\n",
        "image_datagen = ImageDataGenerator(rotation_range=15.,\n",
        "                                   zoom_range=0.2,\n",
        "                                   width_shift_range=0.1,\n",
        "                                   height_shift_range=0.1)\n",
        "\n",
        "# take a random image from the training set\n",
        "img_rgb = X_train[0]\n",
        "\n",
        "# plot the original image\n",
        "plt.figure(figsize=(1,1))\n",
        "plt.imshow(img_rgb)\n",
        "plt.title('Example of RGB image (class = {})'.format(y_train[0]))\n",
        "plt.show()\n",
        "\n",
        "# plot some randomly augmented images\n",
        "rows, cols = 4, 10\n",
        "fig, ax_array = plt.subplots(rows, cols)\n",
        "for ax in ax_array.ravel():\n",
        "    augmented_img, _ = image_datagen.flow(np.expand_dims(img_rgb, 0), y_train[0:1]).next()\n",
        "    ax.imshow(np.uint8(np.squeeze(augmented_img)))\n",
        "plt.setp([a.get_xticklabels() for a in ax_array.ravel()], visible=False)\n",
        "plt.setp([a.get_yticklabels() for a in ax_array.ravel()], visible=False)\n",
        "plt.suptitle('Random examples of data augmentation (starting from the previous image)')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ito5_rr-QeV8"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.contrib.layers import flatten\n",
        "\n",
        "\n",
        "def weight_variable(shape, mu=0, sigma=0.1):\n",
        "    initialization = tf.truncated_normal(shape=shape, mean=mu, stddev=sigma)\n",
        "    return tf.Variable(initialization)\n",
        "\n",
        "\n",
        "def bias_variable(shape, start_val=0.1):\n",
        "    initialization = tf.constant(start_val, shape=shape)\n",
        "    return tf.Variable(initialization)\n",
        "\n",
        "\n",
        "def conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME'):\n",
        "    return tf.nn.conv2d(input=x, filter=W, strides=strides, padding=padding)\n",
        "\n",
        "\n",
        "def max_pool_2x2(x):\n",
        "    return tf.nn.max_pool(value=x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
        "\n",
        "\n",
        "# network architecture definition\n",
        "def my_net(x, n_classes):\n",
        "\n",
        "    c1_out = 64\n",
        "    conv1_W = weight_variable(shape=(3, 3, 1, c1_out))\n",
        "    conv1_b = bias_variable(shape=(c1_out,))\n",
        "    conv1 = tf.nn.relu(conv2d(x, conv1_W) + conv1_b)\n",
        "\n",
        "    pool1 = max_pool_2x2(conv1)\n",
        "\n",
        "    drop1 = tf.nn.dropout(pool1, keep_prob=keep_prob)\n",
        "\n",
        "    c2_out = 128\n",
        "    conv2_W = weight_variable(shape=(3, 3, c1_out, c2_out))\n",
        "    conv2_b = bias_variable(shape=(c2_out,))\n",
        "    conv2 = tf.nn.relu(conv2d(drop1, conv2_W) + conv2_b)\n",
        "\n",
        "    pool2 = max_pool_2x2(conv2)\n",
        "\n",
        "    drop2 = tf.nn.dropout(pool2, keep_prob=keep_prob)\n",
        "\n",
        "    fc0 = tf.concat(1, [flatten(drop1), flatten(drop2)])\n",
        "\n",
        "    fc1_out = 64\n",
        "    fc1_W = weight_variable(shape=(fc0._shape[1].value, fc1_out))\n",
        "    fc1_b = bias_variable(shape=(fc1_out,))\n",
        "    fc1 = tf.matmul(fc0, fc1_W) + fc1_b\n",
        "\n",
        "    drop_fc1 = tf.nn.dropout(fc1, keep_prob=keep_prob)\n",
        "\n",
        "    fc2_out = n_classes\n",
        "    fc2_W = weight_variable(shape=(drop_fc1._shape[1].value, fc2_out))\n",
        "    fc2_b = bias_variable(shape=(fc2_out,))\n",
        "    logits = tf.matmul(drop_fc1, fc2_W) + fc2_b\n",
        "\n",
        "    return logits\n",
        "\n",
        "\n",
        "# placeholders\n",
        "x = tf.placeholder(dtype=tf.float32, shape=(None, 32, 32, 1))\n",
        "y = tf.placeholder(dtype=tf.int32, shape=None)\n",
        "keep_prob = tf.placeholder(tf.float32)\n",
        "\n",
        "\n",
        "# training pipeline\n",
        "lr = 0.001\n",
        "logits = my_net(x, n_classes=n_classes)\n",
        "cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y)\n",
        "loss_function = tf.reduce_mean(cross_entropy)\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=lr)\n",
        "train_step = optimizer.minimize(loss=loss_function)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "unNntKh1QeWA"
      },
      "source": [
        "# metrics and functions for model evaluation\n",
        "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.cast(y, tf.int64))\n",
        "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "def evaluate(X_data, y_data):\n",
        "    \n",
        "    num_examples = X_data.shape[0]\n",
        "    total_accuracy = 0\n",
        "    \n",
        "    sess = tf.get_default_session()\n",
        "    for offset in range(0, num_examples, BATCHSIZE):\n",
        "        batch_x, batch_y = X_data[offset:offset+BATCHSIZE], y_data[offset:offset+BATCHSIZE]\n",
        "        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y, keep_prob: 1.0})\n",
        "        total_accuracy += accuracy * len(batch_x)\n",
        "        \n",
        "    return total_accuracy / num_examples\n",
        "\n",
        "# create a checkpointer to log the weights during training\n",
        "checkpointer = tf.train.Saver()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "tOHacBZ8QeWC"
      },
      "source": [
        "# training hyperparameters\n",
        "BATCHSIZE = 128\n",
        "EPOCHS = 30\n",
        "BATCHES_PER_EPOCH = 5000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRBX0xWlQeWD"
      },
      "source": [
        "# start training\n",
        "with tf.Session() as sess:\n",
        "\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "\n",
        "        print(\"EPOCH {} ...\".format(epoch + 1))\n",
        "\n",
        "        batch_counter = 0\n",
        "        for batch_x, batch_y in image_datagen.flow(X_train_norm, y_train, batch_size=BATCHSIZE):\n",
        "\n",
        "            batch_counter += 1\n",
        "            sess.run(train_step, feed_dict={x: batch_x, y: batch_y, keep_prob: 0.5})\n",
        "\n",
        "            if batch_counter == BATCHES_PER_EPOCH:\n",
        "                break\n",
        "\n",
        "        # at epoch end, evaluate accuracy on both training and validation set\n",
        "        train_accuracy = evaluate(X_train_norm, y_train)\n",
        "        val_accuracy = evaluate(X_val_norm, y_val)\n",
        "        print('Train Accuracy = {:.3f} - Validation Accuracy: {:.3f}'.format(train_accuracy, val_accuracy))\n",
        "        \n",
        "        # log current weights\n",
        "        checkpointer.save(sess, save_path='../checkpoints/traffic_sign_model.ckpt', global_step=epoch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4zH3jr4QeWF"
      },
      "source": [
        "# testing the model\n",
        "with tf.Session() as sess:\n",
        "\n",
        "    # restore saved session with highest validation accuracy\n",
        "    checkpointer.restore(sess, '../checkpoints/traffic_sign_model.ckpt-27')\n",
        "    \n",
        "    test_accuracy = evaluate(X_test_norm, y_test)\n",
        "    print('Performance on test set: {:.3f}'.format(test_accuracy))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrA13xzzQeWJ"
      },
      "source": [
        "### Load the images and plot them here.\n",
        "import os\n",
        "\n",
        "# load new images\n",
        "new_images_dir = '../other_signs'\n",
        "new_test_images = [os.path.join(new_images_dir, f) for f in os.listdir(new_images_dir)]\n",
        "new_test_images = [cv2.cvtColor(cv2.imread(f), cv2.COLOR_BGR2RGB) for f in new_test_images]\n",
        "\n",
        "# manually annotated labels for these new images\n",
        "new_targets = [1, 13, 17, 35, 40]\n",
        "\n",
        "# plot new test images\n",
        "fig, axarray = plt.subplots(1, len(new_test_images))\n",
        "for i, ax in enumerate(axarray.ravel()):\n",
        "    ax.imshow(new_test_images[i])\n",
        "    ax.set_title('{}'.format(i))\n",
        "    plt.setp(ax.get_xticklabels(), visible=False)\n",
        "    plt.setp(ax.get_yticklabels(), visible=False)\n",
        "    ax.set_xticks([]), ax.set_yticks([])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJ1dY9GhQeWN"
      },
      "source": [
        "# first things first: feature preprocessing\n",
        "new_test_images_norm = preprocess_features(new_test_images)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "\n",
        "    # restore saved session\n",
        "    checkpointer.restore(sess, '../checkpoints/traffic_sign_model.ckpt-27')\n",
        "\n",
        "    # predict on unseen images\n",
        "    prediction = np.argmax(np.array(sess.run(logits, feed_dict={x: new_test_images_norm, keep_prob: 1.})), axis=1)\n",
        "\n",
        "for i, pred in enumerate(prediction):\n",
        "    print('Image {} - Target = {:02d}, Predicted = {:02d}'.format(i, new_targets[i], pred))\n",
        "    \n",
        "print('> Model accuracy: {:.02f}'.format(np.sum(new_targets==prediction)/len(new_targets)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdeKQS2dQeWP"
      },
      "source": [
        "# visualizing softmax probabilities\n",
        "with tf.Session() as sess:\n",
        "\n",
        "    # restore saved session\n",
        "    checkpointer.restore(sess, '../checkpoints/traffic_sign_model.ckpt-27')\n",
        "\n",
        "    # certainty of predictions\n",
        "    K = 3\n",
        "    top_3 = sess.run(tf.nn.top_k(logits, k=K), feed_dict={x: new_test_images_norm, keep_prob: 1.})\n",
        "\n",
        "    # compute softmax probabilities\n",
        "    softmax_probs = sess.run(tf.nn.softmax(logits), feed_dict={x: new_test_images_norm, keep_prob: 1.})\n",
        "\n",
        "# plot softmax probs along with traffic sign examples\n",
        "n_images = new_test_images_norm.shape[0]\n",
        "fig, axarray = plt.subplots(n_images, 2)\n",
        "plt.suptitle('Visualization of softmax probabilities for each example', fontweight='bold')\n",
        "for r in range(0, n_images):\n",
        "    axarray[r, 0].imshow(np.squeeze(new_test_images[r]))\n",
        "    axarray[r, 0].set_xticks([]), axarray[r, 0].set_yticks([])\n",
        "    plt.setp(axarray[r, 0].get_xticklabels(), visible=False)\n",
        "    plt.setp(axarray[r, 0].get_yticklabels(), visible=False)\n",
        "    axarray[r, 1].bar(np.arange(n_classes), softmax_probs[r])\n",
        "    axarray[r, 1].set_ylim([0, 1])\n",
        "    \n",
        "# print top K predictions of the model for each example, along with confidence (softmax score)    \n",
        "for i in range(len(new_test_images)):\n",
        "    print('Top {} model predictions for image {} (Target is {:02d})'.format(K, i, new_targets[i]))\n",
        "    for k in range(K):\n",
        "        top_c = top_3[1][i][k]\n",
        "        print('   Prediction = {:02d} with confidence {:.2f}'.format(top_c, softmax_probs[i][top_c]))\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}